{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to test finetuned Helsinki-NLP/opus-mt-eng-hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "import evaluate\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1) Loading the finetuned model, test and benchmark datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare the training and any other dataset\n",
    "def prepare_data(eng_file_path, mai_file_path, data_type):\n",
    "    # load the english and maithili texts files\n",
    "    with open(eng_file_path, \"r\", encoding=\"utf-8\") as en_file:\n",
    "        eng_texts = en_file.readlines()\n",
    "\n",
    "    with open(mai_file_path, \"r\", encoding=\"utf-8\") as maithili_file:\n",
    "        mai_texts = maithili_file.readlines()\n",
    "\n",
    "    assert len(eng_texts) == len(mai_texts), \"The number of sentences in both files must be the same.\"\n",
    "\n",
    "    # clean the text files\n",
    "    eng_texts_cleaned = [text.strip() for text in eng_texts]\n",
    "    mai_texts_cleaned = [text.strip() for text in mai_texts]\n",
    "\n",
    "    # create the dataset\n",
    "    data = {\n",
    "        \"source_text\": eng_texts_cleaned,\n",
    "        \"target_text\": mai_texts_cleaned, \n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    # split the dataset into train, validation and test sets\n",
    "    if data_type == \"train\":\n",
    "        train_dataset, temp_dataset = dataset.train_test_split(test_size=0.1).values()\n",
    "        val_dataset, test_dataset = temp_dataset.train_test_split(test_size=0.5).values()\n",
    "\n",
    "        print(f\"Training set size: {len(train_dataset)}\")\n",
    "        print(f\"Validation set size: {len(val_dataset)}\")\n",
    "        print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    elif data_type == \"test\":\n",
    "        return dataset\n",
    "\n",
    "# preprocessor function for tokenizer\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    inputs = tokenizer(examples[\"source_text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    targets = tokenizer(examples[\"target_text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# function to tokenize the data\n",
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    dataset_tokenized = dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
    "    return dataset_tokenized\n",
    "\n",
    "# function to move the dataset to device\n",
    "def move_to_device(batch):\n",
    "    # move each tensor in the batch to the MPS device\n",
    "    for key in batch:\n",
    "        batch[key] = torch.tensor(batch[key]).to(device)\n",
    "    return batch\n",
    "\n",
    "# function to batch predict the model\n",
    "def trainer_evaluate(model, tokenizer, test_dataset):\n",
    "\n",
    "    eval_trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args = Seq2SeqTrainingArguments(\n",
    "            output_dir=\"./results/test/\",\n",
    "            per_device_eval_batch_size=32,\n",
    "            predict_with_generate=True,\n",
    "            disable_tqdm=False,\n",
    "        ), \n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    return eval_trainer\n",
    "\n",
    "# function to evaluate the model\n",
    "def compute_chrf(predictions, references):\n",
    "    chrf = evaluate.load(\"chrf\")\n",
    "    chrf_score = chrf.compute(predictions=predictions, references=references, word_order=2)\n",
    "    return chrf_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter size: 77265920\n",
      "Parameter size after merging: 76381184\n"
     ]
    }
   ],
   "source": [
    "# load the model and tokenizer\n",
    "model_path = \"./finetuned/epoch2\"\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "print(\"Parameter size:\", finetuned_model.num_parameters())\n",
    "\n",
    "# load the merged model as peft model\n",
    "merged_model = PeftModel.from_pretrained(finetuned_model, model_path)\n",
    "\n",
    "# merge the LoRA weights into the model\n",
    "merged_model.merge_and_unload()\n",
    "\n",
    "# affter merging, get the parameter size\n",
    "print(\"Parameter size after merging:\", merged_model.num_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e0296c083643d48c15c67c2007a244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fae1778fa1ef48e8a71df587563c73ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 1200\n",
      "IN22 benchmark dataset size: 1024\n"
     ]
    }
   ],
   "source": [
    "# read test and benchmark data\n",
    "test_dataset = prepare_data(\"./dataset/training_split/bpcc/test.eng_Latn\", \"./dataset/training_split/bpcc/test.mai_Deva\", \"test\")\n",
    "\n",
    "# choose random 1200 examples from test dataset for faster inference and evaluation\n",
    "test_dataset = test_dataset.shuffle(seed=42).select(range(1200))\n",
    "test_dataset_tokenized = tokenize_dataset(test_dataset, finetuned_tokenizer)\n",
    "\n",
    "in22_mai_test = prepare_data(\"./dataset/test/IN22_test/gen/test.eng_Latn\", \"./dataset//test/IN22_test/gen/test.mai_Deva\", \"test\")\n",
    "in22_mai_test_tokenized = tokenize_dataset(in22_mai_test, finetuned_tokenizer)\n",
    "\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"IN22 benchmark dataset size:\", len(in22_mai_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2) Testing on BPCC Eng-Mai test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f5c2b706044fe2bdae817ca6ba593b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# move the model and in22 testdata to the MPS device\n",
    "merged_model = merged_model.to(device)\n",
    "test_dataset_tokenized = test_dataset_tokenized.with_transform(move_to_device)\n",
    "\n",
    "# generate predictions for english to hindi\n",
    "eval_trainer = trainer_evaluate(merged_model, finetuned_tokenizer, test_dataset_tokenized)\n",
    "test_dataset_mai_pred, test_dataset_mai_lab, _ = eval_trainer.predict(test_dataset_tokenized)\n",
    "\n",
    "# decode the predictions and references\n",
    "test_dataset_mai_pred = finetuned_tokenizer.batch_decode(test_dataset_mai_pred, skip_special_tokens=True)\n",
    "test_dataset_mai_ref = finetuned_tokenizer.batch_decode(test_dataset_mai_lab, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing results for test dataset\n",
      "\n",
      "English Text :  Authorities have asked for a DNA test to confirm the girl's identity.\n",
      "Maithili Reference:  अधिकारी लड़कीक पानक प्टि करबाक लेल डीएनए जा करबाक लेल कहने  ।\n",
      "Maithili Prediction:  एकर प्रार प्रक प्रारार समे प्रूप्रार समे प्राइत समे प्राइत प्रूप्र्त प्राइत प्राइत प्राइत प्र्र्त समेलेल छल छल।\n",
      "\n",
      "\n",
      "English Text :  For example, you might know that a sweater’s original price is $69, and that it is on sale for $51.75.\n",
      "Maithili Reference:  उदाहरण लेल, ा बल हो जे एक टा स्वेटरक मूल दाम  डॉलर  आ ई ५१.७५ डॉलरमे सेलमे बिका रहल\n",
      "Maithili Prediction:  एकर समे एकर समे एकर प्रूर प्रार्त समे समे समे प्राइत प्राइत समे समे प्रूराइत प्राइत छल छलेल छल छल छलेल छल छल छल छल छल छल छल।\n",
      "\n",
      "\n",
      "chrF++ score for English-Maithili test data split: 6.712408945695135\n"
     ]
    }
   ],
   "source": [
    "# print the predictions and references for comparison\n",
    "print(\"Testing results for test dataset\\n\")\n",
    "for i in range(2):\n",
    "    print(\"English Text : \", test_dataset[i]['source_text'])\n",
    "    print(\"Maithili Reference: \", test_dataset_mai_ref[i])\n",
    "    print(\"Maithili Prediction: \",test_dataset_mai_pred[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# calculate chrF++ score for hindi to maithili overlap\n",
    "chrf_score_mai = compute_chrf(test_dataset_mai_pred, test_dataset_mai_ref)\n",
    "print(f\"chrF++ score for English-Maithili test data split: {chrf_score_mai['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3) Testing on IN22 Eng-Mai benchmark dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2aa5125de04a00946231bf56c8c4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# move the model and in22 testdata to the MPS device\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "in22_mai_test_tokenized = in22_mai_test_tokenized.with_transform(move_to_device)\n",
    "\n",
    "# generate predictions for english to hindi\n",
    "eval_trainer = trainer_evaluate(finetuned_model, finetuned_tokenizer, in22_mai_test_tokenized)\n",
    "in22_mai_test_pred, in22_mai_test_lab, _ = eval_trainer.predict(in22_mai_test_tokenized)\n",
    "\n",
    "# decode the predictions and references\n",
    "in22_mai_test_pred = finetuned_tokenizer.batch_decode(in22_mai_test_pred, skip_special_tokens=True)\n",
    "in22_mai_test_ref = finetuned_tokenizer.batch_decode(in22_mai_test_lab, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Text:  An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.\n",
      "Maithili Reference:  रूप सर्ला व्यक् सम्बन् ब रास लक् सम होयत  जेना हुनक ा, कपड़ा, टाई, गहना, , श्रृंगार, ़ी, प्रसाधन सामग्री, सेंट इत्या\n",
      "Maithili Prediction:  एकरा प्रार प्रार्तार प्रार प्रार्तार, समे प्रामे, प्र्रारार, समे, प्र्र्रारार, प्र्र्र्रारारारार, स्त्रारारारारारार, क, स्त्र्रारारारारारारारार्त, ल, ल, ल, स्त्त्मेल, स्त्त्त, लेलेलेलेलेलेलेल, छल, छलेलेलेल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छल, छलेल, छल, छल, छलेलेलेलेल, छलेल, छल, छल, छल, छल, छल, छल, छल, छल, छल।\n",
      "\n",
      "\n",
      "English Text:  Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.\n",
      "Maithili Reference:  महाराष्ट्रके औरंगाबादमे स्थित न्तामे पल ाब्दी ा पूर्व  पाम ाब्दी धरिक मूर्तिकला आ चित्रकला  ाओल उन्नतीस टा ्य आ ार\n",
      "Maithili Prediction:  ई एकारारा प्रारारा प्रारारार प्र्रारा प्रारा प्रारार्रार्रा प्रार्रार्र्रा प्र्रारार्र्र्रार्रारा स्तारारारार्र्रारारार्र्र्र्रा स्त्रारारार्रारारा स्तारारार्र्र्त स्तार्त्त्त स्त्त्त्त्त्त्त्त्त्त्त्तीक स्त्त्त्त्त्त स्त्त्त्त्त्त्त्त्त्त स्त्त स्तारार पर्त स्त प्रार्रारारारारारारारारारारारारारारा प प स्य स्री प्रार्र्र्रारारार्र्र्र्र्रारार्र्रारार्र प प प्त प्त पर्त्त्त्त प्ती प्ताइत पर्र्ताइताइतीक क क क क क क क क क क क क क क क क क क समेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेलेल\n",
      "\n",
      "\n",
      "chrF++ score for English-Maithili IN22 benchmark dataset: 6.3063203842248505\n"
     ]
    }
   ],
   "source": [
    "# print the predictions and references for comparison\n",
    "for i in range(2):\n",
    "    print(\"English Text: \", in22_mai_test[i][\"source_text\"])\n",
    "    print(\"Maithili Reference: \", in22_mai_test_ref[i])\n",
    "    print(\"Maithili Prediction: \", in22_mai_test_pred[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# calculate chrF++ score for hindi to maithili overlap\n",
    "chrf_score_mai = compute_chrf(in22_mai_test_pred, in22_mai_test_ref)\n",
    "print(f\"chrF++ score for English-Maithili IN22 benchmark dataset: {chrf_score_mai['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
