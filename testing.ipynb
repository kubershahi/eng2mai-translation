{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/work/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/miniconda3/envs/work/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <843938F4-8FEE-3058-B0A3-50B73FAF02AB> /opt/miniconda3/envs/work/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/miniconda3/envs/work/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/work/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/work/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/miniconda3/envs/work/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"mps\")\n",
    "\n",
    "import evaluate\n",
    "import sacrebleu\n",
    "from tqdm import tqdm\n",
    "\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1) Loading the finetuned model, test and benchmark datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to prepare the training and any other dataset\n",
    "def prepare_data(eng_file_path, mai_file_path, data_type):\n",
    "    # load the english and maithili texts files\n",
    "    with open(eng_file_path, \"r\", encoding=\"utf-8\") as en_file:\n",
    "        eng_texts = en_file.readlines()\n",
    "\n",
    "    with open(mai_file_path, \"r\", encoding=\"utf-8\") as maithili_file:\n",
    "        mai_texts = maithili_file.readlines()\n",
    "\n",
    "    assert len(eng_texts) == len(mai_texts), \"The number of sentences in both files must be the same.\"\n",
    "\n",
    "    # clean the text files\n",
    "    eng_texts_cleaned = [text.strip() for text in eng_texts]\n",
    "    mai_texts_cleaned = [text.strip() for text in mai_texts]\n",
    "\n",
    "    # create the dataset\n",
    "    data = {\n",
    "        \"source_text\": eng_texts_cleaned,\n",
    "        \"target_text\": mai_texts_cleaned, \n",
    "    }\n",
    "    dataset = Dataset.from_dict(data)\n",
    "\n",
    "    # split the dataset into train, validation and test sets\n",
    "    if data_type == \"train\":\n",
    "        train_dataset, temp_dataset = dataset.train_test_split(test_size=0.1).values()\n",
    "        val_dataset, test_dataset = temp_dataset.train_test_split(test_size=0.5).values()\n",
    "\n",
    "        print(f\"Training set size: {len(train_dataset)}\")\n",
    "        print(f\"Validation set size: {len(val_dataset)}\")\n",
    "        print(f\"Test set size: {len(test_dataset)}\")\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    elif data_type == \"test\":\n",
    "        return dataset\n",
    "\n",
    "# preprocessor function for tokenizer\n",
    "def preprocess_function(examples, tokenizer):\n",
    "    inputs = tokenizer(examples[\"source_text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    targets = tokenizer(examples[\"target_text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# function to tokenize the data\n",
    "def tokenize_dataset(dataset, tokenizer):\n",
    "    dataset_tokenized = dataset.map(lambda x: preprocess_function(x, tokenizer), batched=True)\n",
    "    return dataset_tokenized\n",
    "\n",
    "# function to move the dataset to device\n",
    "def move_to_device(batch):\n",
    "    # move each tensor in the batch to the MPS device\n",
    "    for key in batch:\n",
    "        batch[key] = torch.tensor(batch[key]).to(device)\n",
    "    return batch\n",
    "\n",
    "# function to batch predict the model\n",
    "def trainer_evaluate(model, tokenizer, test_dataset):\n",
    "\n",
    "    eval_trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args = Seq2SeqTrainingArguments(\n",
    "            output_dir=\"./results/test/\",\n",
    "            per_device_eval_batch_size=32,\n",
    "            predict_with_generate=True,\n",
    "            disable_tqdm=False,\n",
    "        ), \n",
    "        eval_dataset=test_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    return eval_trainer\n",
    "\n",
    "# function to evaluate the model\n",
    "def compute_chrf(predictions, references):\n",
    "    chrf = evaluate.load(\"chrf\")\n",
    "    chrf_score = chrf.compute(predictions=predictions, references=references, word_order=2)\n",
    "    return chrf_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter size: 76676096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28927ee0103a48cab0f7181b0c5dd444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9e85697ba34ce2aa47e58a7c0e1bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 1200\n",
      "IN22 benchmark dataset size: 1024\n"
     ]
    }
   ],
   "source": [
    "# load the model and tokenizer\n",
    "model_path  = \"./finetuned/epoch1\"\n",
    "finetuned_tokenizer = AutoTokenizer.from_pretrained(model_path) \n",
    "finetuned_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "print(\"Parameter size:\", finetuned_model.num_parameters())\n",
    "\n",
    "# read test and benchmark data\n",
    "test_dataset = prepare_data(\"./dataset/training_split/bpcc/test.eng_Latn\", \"./dataset/training_split/bpcc/test.mai_Deva\", \"test\")\n",
    "\n",
    "# choose random 1200 examples from test dataset for faster inference and evaluation\n",
    "test_dataset = test_dataset.shuffle(seed=42).select(range(1200))\n",
    "test_dataset_tokenized = tokenize_dataset(test_dataset, finetuned_tokenizer)\n",
    "\n",
    "in22_mai_test = prepare_data(\"./dataset/test/IN22_test/gen/test.eng_Latn\", \"./dataset//test/IN22_test/gen/test.mai_Deva\", \"test\")\n",
    "in22_mai_test_tokenized = tokenize_dataset(in22_mai_test, finetuned_tokenizer)\n",
    "\n",
    "print(\"Test dataset size:\", len(test_dataset))\n",
    "print(\"IN22 benchmark dataset size:\", len(in22_mai_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2) Testing on BPCC Eng-Mai test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f383319adc04c7a96a56d36fc4fbb20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# move the model and in22 testdata to the MPS device\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "test_dataset_tokenized = test_dataset_tokenized.with_transform(move_to_device)\n",
    "\n",
    "# generate predictions for english to hindi\n",
    "eval_trainer = trainer_evaluate(finetuned_model, finetuned_tokenizer, test_dataset_tokenized)\n",
    "test_dataset_mai_pred, test_dataset_mai_lab, _ = eval_trainer.predict(test_dataset_tokenized)\n",
    "\n",
    "# decode the predictions and references\n",
    "test_dataset_mai_pred = finetuned_tokenizer.batch_decode(test_dataset_mai_pred, skip_special_tokens=True)\n",
    "test_dataset_mai_ref = finetuned_tokenizer.batch_decode(test_dataset_mai_lab, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing results for test dataset\n",
      "\n",
      "English Text :  However, the Chola dynasty seemed to have survived elsewhere outside of India.\n",
      "Maithili Reference:  ओना भार बाहर आन ठाम चोल वंश बचि गेल बाइत छल।\n",
      "Maithili Prediction:  एकार प्र्रार्रारा प्र्रारार स्रार्रारा स्रारारा स्रेलेलेल स्र्रेल लेलेलेलेल लेलेलेलेल प्रेलेलेलेलेलेलेलेल प्रेलेलेल प्रेलेलेल क लेलेलेलेलेलेलेलेलेलेलेल लेलेलेलेल।\n",
      "\n",
      "\n",
      "English Text :  Rockport is a city in the U.S. state of Texas.\n",
      "Maithili Reference:  रॉकपोर्ट सन््त राज्य अमेरिका क टेक्सास राज्य क एकटा र थी\n",
      "Maithili Prediction:  एकार स्र्र्र्र्र्रा स्र्र्र्रारा स्र्रार्रा स्र्र्राल स्रेल स्रेल स्रेल स्रेल स्रेलेल स्रेलेलेलेल स्रेल स्रेलेल।\n",
      "\n",
      "\n",
      "chrF++ score for English-Maithili test data split: 5.077240987101195\n"
     ]
    }
   ],
   "source": [
    "# print the predictions and references for comparison\n",
    "print(\"Testing results for test dataset\\n\")\n",
    "for i in range(2):\n",
    "    print(\"English Text : \", test_dataset[i]['source_text'])\n",
    "    print(\"Maithili Reference: \", test_dataset_mai_ref[i])\n",
    "    print(\"Maithili Prediction: \",test_dataset_mai_pred[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# calculate chrF++ score for hindi to maithili overlap\n",
    "chrf_score_mai = compute_chrf(test_dataset_mai_pred, test_dataset_mai_ref)\n",
    "print(f\"chrF++ score for English-Maithili test data split: {chrf_score_mai['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3) Testing on IN22 Eng-Mai benchmark dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43eb9aa372564d2db44f7b91cda3adc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# move the model and in22 testdata to the MPS device\n",
    "finetuned_model = finetuned_model.to(device)\n",
    "in22_mai_test_tokenized = in22_mai_test_tokenized.with_transform(move_to_device)\n",
    "\n",
    "# generate predictions for english to hindi\n",
    "eval_trainer = trainer_evaluate(finetuned_model, finetuned_tokenizer, in22_mai_test_tokenized)\n",
    "in22_mai_test_pred, in22_mai_test_lab, _ = eval_trainer.predict(in22_mai_test_tokenized)\n",
    "\n",
    "# decode the predictions and references\n",
    "in22_mai_test_pred = finetuned_tokenizer.batch_decode(in22_mai_test_pred, skip_special_tokens=True)\n",
    "in22_mai_test_ref = finetuned_tokenizer.batch_decode(in22_mai_test_lab, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Text:  An appearance is a bunch of attributes related to the service person, like their shoes, clothes, tie, jewellery, hairstyle, make-up, watch, cosmetics, perfume, etc.\n",
      "Maithili Reference:  रूप सर्ला व्यक् सम्बन् ब रास लक् सम होयत  जेना हुनक ा, कपड़ा, टाई, गहना, , श्रृंगार, ़ी, प्रसाधन सामग्री, सेंट इत्या\n",
      "Maithili Prediction:  एकार प्र्र्रार्र्र्रा प्र्रार्र्रा प्र्र्र्र्र्र्र्र्र्र्रा पर्र्र्र्र्र्र्रा प्र्र्र्र्रार्र्र्रान स्र्र्र्र्र्रान पार्र्रान प्र्रेल, स्र्र्र्रेलेल प्रेलेलेलेलेल स्र्र्र्र्र्रेलेलेल, स्रेलेलेलेलेलेलेलेलेलेलेलेलेलेल, स्त्त्रेल, स्त्त्रेलेलेलेल, स्त्त्र्र्र्र्थ्र्रेल, स्रेल, लेलेल, लेल, लेलेलेलेलेलेल, पे पेलेलेलेलेलेलेल, लेल, लेल, लेलेलेलेलेलेल, लेलेलेलेलेलेलेल, लेल, लेलेलेलेल, लेलेल लेल, ल ल लेलेलेलेल ल आ लेलेलेलेल।\n",
      "\n",
      "\n",
      "English Text:  Ajanta, located in the Aurangabad District of Maharashtra has twenty-nine caitya and vihara caves decorated with sculptures and paintings from the first century B.C.E. to the fifth century C.E.\n",
      "Maithili Reference:  महाराष्ट्रके औरंगाबादमे स्थित न्तामे पल ाब्दी ा पूर्व  पाम ाब्दी धरिक मूर्तिकला आ चित्रकला  ाओल उन्नतीस टा ्य आ ार\n",
      "Maithili Prediction:  प्र्रारा प्र्रार्र्र्र्र्रार प्र्र्रार्रा प्र्र्रार्र्र्र्रार्र्रान प्र्र्र्र्र्र्र्र्र्रारार्र्रान स्रारारार्र्रान पार्र्र्रान पार्र्र्र्र्र्र्रेल स्र्रेल स्र्र्र्र्र्राल पार्र्र्र्र्र्र्र्रानानानानान पाराल स्र्र्र्र्राल पाल स्र्र्र्र्र्राराराल स्राल स्र्र्र्राल स्र्राराराराल पार्राल पाल पाल पाराराली क क स्राल पारारालाल स्र्रेलेल क स्र्रार्र्र्रारार्र्र्र्र्र्थ स्र्रेलेल क क क क क क क क क स्र्र्र्र्र्र्राल ल ल स्र्र्र्र्र्र्राल ल ल पर्र्र्र्राल पर्र्र्र्र्र्र्र्र्र्र्र्रल पर्र्र्र्र्र्र्र्र्र्र्राल ल ल\n",
      "\n",
      "\n",
      "chrF++ score for English-Maithili IN22 benchmark dataset: 5.130268430008663\n"
     ]
    }
   ],
   "source": [
    "# print the predictions and references for comparison\n",
    "for i in range(2):\n",
    "    print(\"English Text: \", in22_mai_test[i][\"source_text\"])\n",
    "    print(\"Maithili Reference: \", in22_mai_test_ref[i])\n",
    "    print(\"Maithili Prediction: \", in22_mai_test_pred[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# calculate chrF++ score for hindi to maithili overlap\n",
    "chrf_score_mai = compute_chrf(in22_mai_test_pred, in22_mai_test_ref)\n",
    "print(f\"chrF++ score for English-Maithili IN22 benchmark dataset: {chrf_score_mai['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
